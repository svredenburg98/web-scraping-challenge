# web-scraping-challenge

This one was difficult! And not perfect.

The goal was to scrape multiple websites using BeautifulSoup, Splinter and Pandas for mars information. I had to inspect the page's html elements to determine what to tell the scraper to look for, which was different for every web page. Most of the pages also did not contain the sought after information in the source, but luckily the chrome extention helped with that. After writing and rewriting code to get all of the desired information, I copy and pasted all of the code into a .py file to use with the flask application. Unfortunately, the image from the JPL website just did not want to scrape when running the .py file. It worked every single time when using the notebook, but not with the python file. I think maybe it was trying to execute the code before the page had loaded. So unfortunately I was not able to get that image to scrape and had to skip it to continue. At the end of the code, I put all of the scraped information into a dictionary, which I could then send to a Mongo database. I then wanted to get the stored information to display in the flask application using an html template. I had to turn the db.find() output into a list, which I could then call individual parts in the html file.
